\documentclass{article}
\usepackage[a4paper, inner=1.7cm, outer=2.7cm, top=2cm, bottom=2cm, bindingoffset=1.2cm]{geometry} 
\usepackage[english]{babel}
\usepackage{blindtext}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{amsfonts} %for using mathbb
\usepackage{index}
\usepackage{import}

\usepackage[bookmarks=true]{hyperref}
\usepackage{bookmark}

\makeindex

%new commands: 
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\innerproduct}[1]{\langle#1\rangle}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\numberwithin{theorem}{subsection} % important bit
\numberwithin{definition}{subsection} % important bit

\begin{document}
\title{\Large{\textbf{Linear Algebra: Map of theorems}}}
\author{Tan Wee Han}
\maketitle

\let\cleardoublepage\clearpage
\tableofcontents

\pagestyle{plain} %remove page headers but keep page numbers

\makeatletter
%\setlength{\@fptop}{0pt} % to put the figure on top of the page.
\makeatother


\section{Bilinear Forms and Inner Product}


\subsection{Vector inequalities}
Cauchy-Schwarz Inequality: $\norm{\innerproduct{u,v}} \leq \norm{u}\norm{v}$ \\
Triangle Inequality: $\norm{u+v} \leq \norm{u} + \norm{v}$ \\
Pythagoras Theorem: $\norm{u+v}^2 = \norm{u}^2 + \norm{v}^2$ \bigskip

\subsection{Orthogonal and Orthonormal basis}
\begin{theorem}
    An orthogonal set of nonzero vectors is linearly independent.
\end{theorem}

\begin{corollary}
    If $V$ is a finite dimensional inner product space and $n=dim V$, then any orthogonal set of nonzero vectors in $V$ is finite and contains at most n vectors.
\end{corollary}

\begin{lemma}
    Let $ \mathcal{B} = \{v_1,...,v_n\}$ be an orthonormal basis of $V$. Then for any $v \in V,$ \\
    \begin{equation*}
        V = \innerproduct{v,v_1}v_1 + \innerproduct{v,v_2}v_2 +...+
        \innerproduct{v,v_n}v_n
    \end{equation*}
\end{lemma}

\begin{corollary}

    Let $ \mathcal{B} = \{v_1,...,v_n\}$ be an orthonormal basis of $V$,
    $T:V\rightarrow V$ a linear operator and $[T]_\mathcal{B} = (a_{ij})$ Then for all $i,j$ \\
    \begin{equation*}
    a_{ij}=\innerproduct{T(v_j), v_i}
    \end{equation*}
\end{corollary}

\begin{theorem}
    Every finite dimensional inner product space has an orthonormal basis.
\end{theorem}



\subsection{Orthogonal complement and projection}
\begin{theorem}
    If $W$ is a subspace of an inner product space V, then its orthogonal complement
    $W^{\perp}$ is a subspace of $V$. In addition, we have
    \begin{equation*}
        W \cap W^{\perp} = \{\mathbf{0}\}
    \end{equation*}
\end{theorem}

\begin{theorem}
    If $W$ is a finite dimensional subspace of an inner product space V, then
    \begin{equation*}
        V = W \oplus W^{\perp} 
    \end{equation*}
\end{theorem}

\begin{theorem}
    If $\{w_1, ..., w_k\}$ is an orthonormal basis of $W$ then 
    \begin{equation*}
        \mathbf{proj}_W(v) = \Sigma^k_{j=1} \innerproduct{v,w_j}w_j
    \end{equation*}
\end{theorem}


\begin{theorem} 
    \textbf{Best Approximation:}
    If $W$ a finite dimensional subspace of an inner product space $V$ and $v \in V$, then
    \begin{equation*}
        \norm{v-\mathbf{proj}_W(v)} < \norm{v-w}
    \end{equation*}
    for every vector $w$ in $W$ different from $\mathbf{proj}_W(v)$.
\end{theorem}



\begin{theorem}
    \textbf{Least Square Solution:}
    For any real linear system $A\mathbf{x} = \mathbf{b}$ the associated normal system 
    \begin{equation*}
        (A^tA)\mathbf{x} = A^t \mathbf{b}
    \end{equation*}
is consistent, and all its solutions are least square solutions of $A\mathbf{x} = \mathbf{b}$
\end{theorem}


\subsection{Adjoint of linear operator}

\begin{theorem}
    Let $V$ be a finite dimensional inner product space over $\mathbb{F}$. If $f:V \rightarrow \mathbb{F}$ is a linear functional, then there exists a unique vector $ u \in V$ such that. 
    \begin{equation*}
        f(v) = \innerproduct{v,u} \qquad \text{for all } v \in V
    \end{equation*}
\end{theorem}

\begin{theorem}
    Let $T: V \rightarrow V$ be a linear operator on a finite dimensional inner product
    space $V$. Then there exists a unique linear operator $T^{*}: V \rightarrow V$ such
    that 
        \begin{equation*}
            \innerproduct{T(u),v} = \innerproduct{u,T^*(v)}
        \end{equation*}
    $T^*$ is called the adjoint of T.
\end{theorem}

\begin{theorem}
    Let $T:V \rightarrow V$ a linear operator on a finite dimensional inner product space
    V and B be an orthonormal basis of V. Then 
        \begin{equation*}
            [T^*]_\mathcal{B} = ([T]_\mathcal{B})^*
        \end{equation*}
        is the conjugate transpose of the matrix $[T]_\mathcal{B}$
\end{theorem}

\begin{theorem}
    Let $T,T_1 \text{ and } T_2$ be linear operators on a finite dimensional inner product
    space V. Then: 
    \begin{flalign*}
        &(i) \quad (T_1 + T_2)^* = T_1^* + T_2^* \\
        &(ii) \quad c(T)^* = \overline{c} T^* \\
        &(iii) \quad (T_1T_2)^* = T_2^*T_1^* \\
        &(iv) \quad (T^*)^* = T \\
    \end{flalign*}
\end{theorem}

\subsection{Self-adjoint and Normal Operator}
Main motivation for this section is to find out under what conditions does $V$ have an
orthonomal basis of eigenvectors for $T$.

\begin{definition}
    A linear operator $T$ on a finite dimensional inner product space V is called
    $\textbf{self-adjoint}$ if $T=T^*$, i.e. it satisfies the equation:
    \begin{equation*}
        \innerproduct{T(u),v} = \innerproduct{u,T(v)}
    \end{equation*}
\end{definition}

\begin{theorem}
    (p. 312)
    A self-adjoint linear operator $T$ on a finite dimensional inner product space V.Then
    all eigenvalues of $T$ is real. And the eigenvectors associated with the distinct
    eigenvalues are orthogonal.
\end{theorem}

\begin{theorem}
    (p. 313)
    On a finite dimensional inner product space of positive dimension, every self-adjoint
    operator has at least one eigenvalue which also means it has at least one eigenvector.\\

    (note proof of this in complex vector space do not require $T$ to be self-adjoint, but in
    real vector space it does)
\end{theorem}

\begin{lemma}\label{lem1}
    Let $V$ be a finite dimensional inner product space. Let $T:V
    \rightarrow V$ be any linear operator. Suppose $W$ is a subspace of $V$ which is
    invariant under T. Then $W^\perp$ is invariant under $T^*$
\end{lemma}

\begin{theorem}
    Let $V$ be a finite dimensional inner product space (complex or real). Let $T:V
    \rightarrow V$ be a self adjoint linear operator. $T$ is orthgonally diagonalizable if
    and only if it is self-adjoint. \\
    (proof uses Lemma \ref{lem1})
\end{theorem}

\begin{corollary}
    Let $A$ be an $n \times n$ Hermitian matrix. Then there is a unitary matrix $P$ such
    that $P^{-1}AP$ is diagonal. (i.e. $A$ is unitariliy equivalent to a diagonal matrix).
    If $A$ is a real symmetric matrix, there is a real orthogonal matrix $P$ such that 
    that $P^{-1}AP$ is diagonal.
\end{corollary}

\begin{definition}
    Let $V$ be a finite dimensional inner product space. Let $T:V \rightarrow V$ be
    a linear operator on V. We say that $T$ is normal if it commutes with its adjoint: 
    \begin{equation*}
        TT^* = T^*T
    \end{equation*}
\end{definition}

\begin{lemma}\label{lem2}
    Let V be a finite dimensional complex inner product space and $T:V\rightarrow V$
    a normal linear operator. Then if $v \in V$ is an eigenvector of $T$ corresponding to
    the eigenvalue $\lambda$, then it is also an eigenvector of $T^*$ corresponding to the
    eigenvalue $\overline{\lambda}$. That is for $v \in V$,
    \begin{equation*}
        T(v) = \lambda v \Rightarrow T^*(v) = \overline{\lambda} v
    \end{equation*}
\end{lemma}

\begin{lemma}\label{lem3}
    Let V be a finite dimensional complex inner product space and $T:V\rightarrow V$
    any linear operator. Then $V$ has an orthonormal basis $\mathcal{B}$ such that matrix
    $[T]_\mathcal{B}$ is upper triangular. 
\end{lemma}

\begin{theorem}
    A linear operator on a finite dimensional complex inner product space is orthogonally
    diagonalizable if and only if it is normal. \\
    (proof uses lemma \ref{lem2} and \ref{lem3})
\end{theorem}
        

\subsection{Unitary Operator}

\begin{theorem}
    Let $V$ and $W$ be a finite dimensional inner product spaces over the same field.  If
    $f : V \rightarrow W$ is a linear transformation, the following are equivalent:

    \begin{enumerate}
        \item $\innerproduct{T(u),T(v)} = \innerproduct{u,v}$ for all $u,v \in V$. i.e. $T$ preserves inner product spaces
        \item $T$ is an inner product space isomorphism
        \item $T$ carries every orthonormal basis for $V$ onto an orthonormal basis for $W$
        \item $\norm{T(v)}=\norm{v}$ for all $v \in V$.
    \end{enumerate}
\end{theorem}

\begin{definition}
    A unitary operator on an inner product space is an isomorphism of the space onto
    itself.
\end{definition}

\begin{theorem}
    Let $T$ be a linear operator on an inner product space V. Then $T$ is unitary if and
    only if the adjoint $T^*$ of  T exists and $TT^*=T^*T = I$
\end{theorem}

\begin{theorem}
    Let $V$ be a finite dimensional inner product space and let $T: V \rightarrow V$ be
    a linear operator. Then $T$ is unitary if and only if the matrix of $T$ in some (or every) ordered basis is
a unitary matrix. 
\end{theorem}

\begin{theorem}
    (p.305)
    For every invertible complex $n \times n$ matrix $B$, there exists a unique lower-triangular
    matrix M with positive entries on the main diagonal such that $MB$ is unitary.
\end{theorem}

\begin{corollary}
    (p.307)
    Let $T^+(n)$ be the set of all complex $n \times n$ lower triangular matrices with
    positive entries on the main diagonal. Let $U(n)$ be a group of unitary matrices. For each $B$ in $GL(n)$ there exists unique matrices $N$ and $U$ such that $N \in
    T^+(n)$ and $U \in U(n)$.
\end{corollary}





\end{document}
